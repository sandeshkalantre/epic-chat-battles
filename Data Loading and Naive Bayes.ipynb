{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Naive Bayes\n",
    "I will use this notebook to establish a pipeline to load data for our experiments. \n",
    "\n",
    "The second aim to establish a Naive Bayes generator capable of generating few lines of dialogue given a context of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111396\n"
     ]
    }
   ],
   "source": [
    "datapath = \"Shakespeare_data.csv\"\n",
    "\n",
    "data = pd.read_csv(datapath)\n",
    "data.keys()\n",
    "\n",
    "# datacleanup\n",
    "# remove all special characters\n",
    "lines_data = []\n",
    "for sentence in data['PlayerLine']:\n",
    "    new_sentence = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        new_sentence.append(re.sub('[^A-Za-z0-9]+','', word.lower()))\n",
    "    lines_data.append(\" \".join(new_sentence))\n",
    "print(len(lines_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Description\n",
    "Let $\\mathcal{V}$ be the vocabulary of words in the dataset. $\\mathcal{S} = \\{\\vec{s_i}\\}$ be the set of sentences in the order as they appear in the dataset. $\\vec{x}$ is a collection of words from $\\mathcal{V}$, defined as the context. Let $d$ be a positive integer called the dialogue depth.\n",
    "\n",
    "### Probabilty Model\n",
    "The task is given a context $\\vec{x}$, predict a most probable set of surrounding sentences $\\{\\vec{s_i}\\}_{i=j-d}^{j-1}$ such that words from $\\vec{x}$ are contained in the set.\n",
    "\n",
    "As a start, the probability is used. $$P(\\vec{x},j | d) \\propto \\sum_{i=1,i \\neq j}^{|x|} \\mathcal{I}(x_i \\in \\cup_{i=j-d}^{j-1}\\vec{s_i})$$\n",
    "\n",
    "where $\\mathcal{I}(...)$ is the indicator function\n",
    "It is basically the count of the number of times words from $\\vec{x}$ appear in sentences $\\{\\vec{s_i}\\}_{i=j-d}^{j-1}$.\n",
    "\n",
    "### Dialogue Prediction\n",
    "The final output dialogue $\\mathcal{D}$ is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "j^* &= \\underset{j}{\\arg\\max} P(\\vec{x},j | d) \\\\\n",
    "\\mathcal{D} &= s_{j^*} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27461\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = list(set((\" \".join(lines_data).split(\" \"))))\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(x,j,d,lines_data):\n",
    "    '''\n",
    "    Calcuates the prob. that context x belongs to sentence set j-d + j\n",
    "        x : context\n",
    "        j : index of the middle sentence\n",
    "        d : dialogue depth\n",
    "        lines_data : list of sentences\n",
    "    '''\n",
    "    # get all words in sentences using the join and split\n",
    "    wordlist = \" \".join(lines_data[j-d:j]).split(\" \")\n",
    "    score = 0\n",
    "    for word in x:\n",
    "        score += wordlist.count(word)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dialogue(x,d,lines_data):\n",
    "    '''\n",
    "    Returns the prob_vec and dialogue with highest score given context x\n",
    "    '''\n",
    "    prob_vec = np.array([prob(x,y,d,lines_data) for y in range(len(lines_data))])\n",
    "    max_score = np.max(prob_vec)\n",
    "    # break ties arbitarily\n",
    "    max_index = np.random.choice(np.argwhere(prob_vec == max_score).flatten())\n",
    "    dialogue = lines_data[max_index]\n",
    "    \n",
    "    return prob_vec,max_index,max_score,dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment I\n",
    "Context is chosen randomly or set manually from the vocabulary and one response is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context words\n",
      " ['king', 'subject']\n",
      "\n",
      "Score\n",
      "8\n",
      "\n",
      "max index\n",
      "80520 \n",
      "\n",
      "the blood of english shall manure the ground\n"
     ]
    }
   ],
   "source": [
    "# dialogue depth\n",
    "d = 20\n",
    "# context_size\n",
    "context_size = 10\n",
    "\n",
    "# choose a random context from V\n",
    "#x = np.random.choice(list(V),context_size)\n",
    "\n",
    "x = [\"king\",\"subject\"]\n",
    "prob_vec,max_index,max_score,dialogue = calc_dialogue(x,d,lines_data)\n",
    "\n",
    "print(\"Context words\\n\",x)\n",
    "\n",
    "print(\"\\nScore\")\n",
    "print(max_score)\n",
    "\n",
    "print(\"\\nmax index\")\n",
    "print(max_index,\"\\n\")\n",
    "print(dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment II\n",
    "A loop of conversation is formed after using the output of first prediction as context for the next prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCTAVIA that have my heart parted betwixt two friends\n",
      "Clown for young charbon the puritan and old poysam the\n",
      "TOUCHSTONE justices could not take up a quarrel but when the\n",
      "TOUCHSTONE of an if as if you said so then i said so and\n",
      "ROSALIND of irish wolves against the moon\n",
      "FLUELLEN if the enemy is an ass and a fool and a prating\n",
      "CARDINAL WOLSEY let silence be commanded\n",
      "PARIS come you to make confession to this father\n",
      "ROSALIND i would love you if i could tomorrow meet me all together\n",
      "HELENA what worser place can i beg in your love\n",
      "HELENA than to be used as you use your dog\n",
      "VIOLA longer some mollification for your giant sweet\n",
      "Sixth Citizen mans voice\n"
     ]
    }
   ],
   "source": [
    "conversation_length = 15\n",
    "d = 10\n",
    "x = [\"king\",\"slave\"]\n",
    "for index in range(conversation_length):\n",
    "    prob_vec,max_index,max_score,dialogue = calc_dialogue(x,d,lines_data)    \n",
    "    result = dialogue\n",
    "    #print(np.argwhere(prob_vec == max_score).flatten())\n",
    "    #print(max_score,max_index)\n",
    "    print(data['Player'][max_index],result)\n",
    "    \n",
    "    # new context\n",
    "    x = result.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
